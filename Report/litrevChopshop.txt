The study experimented with two datasets. First, the Convote dataset, which contained ideologically-labelled US Congress debates from 2005, labelled at a sentence level. Second, the Ideological Books Corpus (IBC), which contained transcripts of strongly-ideological books and labels relating to the writersâ€™ political alignment. The IBC was also later annotated at a phrase-level through crowdsourcing to examine whether the performance of the RNN would change if a finer level of annotation was used to train it. Efforts were taken to filter both datasets to ensure that the training data only included text that was explicitly and visibly biased to the human eye.